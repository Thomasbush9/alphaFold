{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup\n",
    "\n",
    "Run the cells below for the basic setup of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No colab environment, assuming local setup.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive # type: ignore\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print('No colab environment, assuming local setup.')\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
    "    # turorials folder, e.g. 'alphafold-decoded/tutorials'\n",
    "    FOLDERNAME = None\n",
    "    assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "    # Now that we've mounted your Drive, this ensures that\n",
    "    # the Python interpreter of the Colab VM can load\n",
    "    # python files from within it.\n",
    "    import sys\n",
    "    sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "    %cd /content/drive/My\\ Drive/$FOLDERNAME\n",
    "\n",
    "    print('Connected COLAB to Google Drive.')\n",
    "\n",
    "import os\n",
    "    \n",
    "base_folder = '../structure_module'\n",
    "control_folder = f'{base_folder}/control_values'\n",
    "\n",
    "assert os.path.isdir(control_folder), 'Folder \"control_values\" not found, make sure that FOLDERNAME is set correctly.' if IN_COLAB else 'Folder \"control_values\" not found, make sure that your root folder is set correctly.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x111a4a8e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import sys\n",
    "base_folder = Path('/Users/thomasbush/Documents/ML/alphafold-decoded/tutorials')\n",
    "\n",
    "# Remove wrong paths if any\n",
    "sys.path = [p for p in sys.path if 'structure_module' not in p]\n",
    "\n",
    "# Add base path again\n",
    "sys.path.insert(0, str(base_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Module\n",
    "\n",
    "The Structure Module is the final part of Alphafold. It takes the single representation from the Evoformer and directly predicts the 3D positions of each heavy atom. So far, the model used very little geometric information. The Evoformer uses mostly grid-based, column-wise or row-wise operations on its inputs. The Structure Module is different in this regard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariant Point Attention\n",
    "\n",
    "Invariant point attention is the core, geometric mechanism in the structure module. The idea is the following: The structure module runs multiple iterations per pass of the full model, updating its current guess on the backbone transforms in each iteration. It starts with a so-called 'Black-Hole-Initialization', where all backbones start at position 0 with identity transforms. The invariant point attention module uses the transforms from the last pass. It samples its query and key points in the local coordinate frames of each amino acid. That means, it's baked into the attention mechanism, that attention is increased for residues that are close to each other (according to the latest guess of the residue's positions). \n",
    "\n",
    "The module is desribed in Algorithm 22. Take a first look at it and start by implementing the `__init__` method and `prepare_qkv` in `ipa.py`. Check your code by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 3, 20])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.randn((20, 3, 4, 5))\n",
    "q.movedim((0, 1),(-1, -2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasbush/Documents/ML/alphafold-decoded/tutorials/structure_module/control_values/structure_module_checks.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_shapes = torch.load(shapes_path)\n",
      "/Users/thomasbush/Documents/ML/alphafold-decoded/tutorials/structure_module/control_values/structure_module_checks.py:131: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_out = torch.load(out_file_name)\n",
      "/Users/thomasbush/Documents/ML/alphafold-decoded/tutorials/structure_module/control_values/structure_module_checks.py:136: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_out = torch.load(out_file_name)\n"
     ]
    }
   ],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_shape, test_module_method\n",
    "from structure_module.control_values.structure_module_checks import c_s, c_z, n_qp, n_pv, N_head, c\n",
    "from structure_module.ipa import InvariantPointAttention\n",
    "\n",
    "ipa = InvariantPointAttention(c_s, c_z, n_qp, n_pv, N_head, c)\n",
    "\n",
    "test_module_shape(ipa, 'ipa', control_folder)\n",
    "\n",
    "test_module_method(ipa, 'ipa_prep', 's', ('q', 'k', 'v', 'qp', 'kp', 'vp'), control_folder, lambda x: ipa.prepare_qkv(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will go through the computation of the attention scores, which is line 5 to line 7 in Algorithm 22. This is where the magic happens. Don't look to much at wc and wl here, they are just picked in a way that, given normal initialization, the three sources of attention - q/k, bias, and qp/kp - contribute about equally to the attention scores, and gamma is a learnable parameter that can adjust this weighting.\n",
    "\n",
    "The interesting part is the contribution of the attention points. `qp` and `kp`, as far as we implemented them, just arise from embedding the single representation. In machine learning, we often assume these values as distributed following a standard normal distribution. This is reinforced by the layer normalization we put in at several stages in the model. This means, `qp` and `kp` are in a spherical, normal distribution around the coordinate origin. \n",
    "\n",
    "But the attention contribution from `qp` and `kp` doesn't arise from this position. Instead, they are warped through the backbone transforms `T` before their difference is computed. This warping through the backbone transforms means interpreting the query and key points as local coordinates in the backbone transforms. The results are the global positions of the key and query points. \n",
    "\n",
    "**In this sense, Alphafold calculates the key and query points by adding an offset to the backbone positions, as inferred by the model so far.**\n",
    "\n",
    "The distance of these key and query points is subtracted from the attention scores, meaning that pairs far apart from each other contribute little to the update, while close pairs contribute strongly.\n",
    "\n",
    "Implement the method `compute_attention_scores` and check your implementation by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasbush/Documents/ML/alphafold-decoded/tutorials/structure_module/control_values/structure_module_checks.py:131: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_out = torch.load(out_file_name)\n",
      "/Users/thomasbush/Documents/ML/alphafold-decoded/tutorials/structure_module/control_values/structure_module_checks.py:136: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_out = torch.load(out_file_name)\n"
     ]
    }
   ],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_method\n",
    "from structure_module.control_values.structure_module_checks import c_s, c_z, n_qp, n_pv, N_head, c\n",
    "from structure_module.ipa import InvariantPointAttention\n",
    "\n",
    "ipa = InvariantPointAttention(c_s, c_z, n_qp, n_pv, N_head, c)\n",
    "\n",
    "test_module_method(ipa, 'ipa_att_scores', ('q', 'k', 'qp', 'kp', 'z', 'T'), 'att', control_folder, lambda *x: ipa.compute_attention_scores(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention scores are used to measure the contribution of three different features to the output: The pair representation `z`, the value vectors `v` and the value points `vp`. The direct computation of these outputs is straightforward, but it's good practice for your einsum strings. \n",
    "\n",
    "Look at line 10 in Algorithm 22 carefully: The value points are mapped through the transform before the attention weighing, that mapped back afterwards. Let's assume first the attention scores are close to a one-hot vector, meaning for fixed indices $i$ and $h$, for one index $j$ the score is 1 while the other ones are 0. Then, this line simplifies to $T_i^{-1} \\circ T_j \\circ \\vec{v}_j^{hp}$. That means the value vector is sampled around the backbone transform of residue $j$, and for the update, the coordinates of this point are calculated with respect to the backbone transform of residue $i$. If the attention scores are not one-hot, the value vectors are sampled around several of the backbone transforms and averaged before being localized to the transform of residue $i$.\n",
    "\n",
    "Implement the method `compute_outputs` and check your implementation by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_method\n",
    "from structure_module.control_values.structure_module_checks import c_s, c_z, n_qp, n_pv, N_head, c\n",
    "from structure_module.ipa import InvariantPointAttention\n",
    "\n",
    "ipa = InvariantPointAttention(c_s, c_z, n_qp, n_pv, N_head, c)\n",
    "\n",
    "test_module_method(ipa, 'ipa_att_outputs', ('att_scores', 'z', 'v', 'vp', 'T'), ('v_out', 'vp_out', 'vp_outnorm', 'pairwise_out'), control_folder, lambda *x: ipa.compute_outputs(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we've got all the complicated parts together. Assemble them in the forward method of `InvariantPointAttention` to finalize the module. Then, check your code with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_forward\n",
    "from structure_module.control_values.structure_module_checks import c_s, c_z, n_qp, n_pv, N_head, c\n",
    "from structure_module.ipa import InvariantPointAttention\n",
    "\n",
    "ipa = InvariantPointAttention(c_s, c_z, n_qp, n_pv, N_head, c)\n",
    "\n",
    "test_module_forward(ipa, 'ipa', ('s', 'z', 'T'), 'out', control_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Module\n",
    "\n",
    "With IPA, the hard part of the Structure Module is already done. The rest is mostly about stitching together a few modules. \n",
    "\n",
    "We'll start with `StructureModuleTransition`, which are lines 8-9 in Algorithm 20. Implement the initialization and forward pass, then check your method with the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasbush/Documents/ML/alphafold-decoded/tutorials/structure_module/control_values/structure_module_checks.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_shapes = torch.load(shapes_path)\n"
     ]
    }
   ],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_forward, test_module_shape, c_s\n",
    "from structure_module.structure_module import StructureModuleTransition\n",
    "\n",
    "transition = StructureModuleTransition(c_s)\n",
    "\n",
    "test_module_shape(transition, 'sm_transition', control_folder)\n",
    "\n",
    "test_module_forward(transition, 'sm_transition', 's', 's_out', control_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is `BackboneUpdate`. All it's doing is embedding the single representation into a 6-value vector, which is split into three values for a quaternion (padded with 1 to reach four values) and three values for a translation. The quaternion is normalized and converted into a rotation matrix. We already implemented this conversion in the geometry section.\n",
    "\n",
    "Implement the initialization and forward pass for `BackboneUpdate`, then check your implementation by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3]) torch.Size([10, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (0) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m bb_update \u001b[38;5;241m=\u001b[39m BackboneUpdate(c_s)\n\u001b[1;32m      6\u001b[0m test_module_shape(bb_update, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbb_update\u001b[39m\u001b[38;5;124m'\u001b[39m, control_folder)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtest_module_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbb_update\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbb_update\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mT_out\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ML/alphafold-decoded/tutorials/structure_module/control_values/structure_module_checks.py:148\u001b[0m, in \u001b[0;36mtest_module_forward\u001b[0;34m(module, test_name, input_names, output_names, control_folder)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_module_forward\u001b[39m(module, test_name, input_names, output_names, control_folder):\n\u001b[0;32m--> 148\u001b[0m     \u001b[43mtest_module_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ML/alphafold-decoded/tutorials/structure_module/control_values/structure_module_checks.py:120\u001b[0m, in \u001b[0;36mtest_module_method\u001b[0;34m(module, test_name, input_names, output_names, control_folder, method, include_batched)\u001b[0m\n\u001b[1;32m    117\u001b[0m     batched_inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(batched_inp)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 120\u001b[0m     non_batched_out \u001b[38;5;241m=\u001b[39m \u001b[43mcontrolled_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_batched_inps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_batched:\n\u001b[1;32m    122\u001b[0m         batched_out \u001b[38;5;241m=\u001b[39m controlled_execution(module, batched_inps, method)\n",
      "File \u001b[0;32m~/Documents/ML/alphafold-decoded/tutorials/structure_module/control_values/structure_module_checks.py:81\u001b[0m, in \u001b[0;36mcontrolled_execution\u001b[0;34m(module, inp, method)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m     79\u001b[0m     param\u001b[38;5;241m.\u001b[39mcopy_(torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, param\u001b[38;5;241m.\u001b[39mnumel())\u001b[38;5;241m.\u001b[39mreshape(param\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m---> 81\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m orig_param, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(original_params, module\u001b[38;5;241m.\u001b[39mparameters()):\n\u001b[1;32m     84\u001b[0m     param\u001b[38;5;241m.\u001b[39mcopy_(orig_param)\n",
      "File \u001b[0;32m~/Documents/ML/alphafold-decoded/tutorials/structure_module/control_values/structure_module_checks.py:148\u001b[0m, in \u001b[0;36mtest_module_forward.<locals>.<lambda>\u001b[0;34m(*x)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_module_forward\u001b[39m(module, test_name, input_names, output_names, control_folder):\n\u001b[0;32m--> 148\u001b[0m     test_module_method(module, test_name, input_names, output_names, control_folder, \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39mx: \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/alphafold/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/alphafold/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/ML/alphafold-decoded/tutorials/structure_module/structure_module.py:124\u001b[0m, in \u001b[0;36mBackboneUpdate.forward\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(translation\u001b[38;5;241m.\u001b[39mshape, quat\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    122\u001b[0m quat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(quat, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 124\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[43mquat_to_3x3_rotation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(R\u001b[38;5;241m.\u001b[39mshape, translation\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    126\u001b[0m T \u001b[38;5;241m=\u001b[39m assemble_4x4_transform(R, translation)\n",
      "File \u001b[0;32m~/Documents/ML/alphafold-decoded/tutorials/geometry/geometry.py:203\u001b[0m, in \u001b[0;36mquat_to_3x3_rotation\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    201\u001b[0m eye \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m3\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mq\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mq\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    202\u001b[0m eye \u001b[38;5;241m=\u001b[39m eye\u001b[38;5;241m.\u001b[39mbroadcast_to(batch_shape\u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m--> 203\u001b[0m e1 \u001b[38;5;241m=\u001b[39m \u001b[43mquat_vector_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meye\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m e2 \u001b[38;5;241m=\u001b[39m quat_vector_mul(q, eye[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    205\u001b[0m e3 \u001b[38;5;241m=\u001b[39m quat_vector_mul(q, eye[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/ML/alphafold-decoded/tutorials/geometry/geometry.py:172\u001b[0m, in \u001b[0;36mquat_vector_mul\u001b[0;34m(q, v)\u001b[0m\n\u001b[1;32m    170\u001b[0m pad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(pad_shape,device\u001b[38;5;241m=\u001b[39mv\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mv\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    171\u001b[0m vect_padded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((pad, v), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m v_out \u001b[38;5;241m=\u001b[39m quat_mul(q, \u001b[43mquat_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvect_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_star\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    173\u001b[0m v_out \u001b[38;5;241m=\u001b[39m v_out[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m##########################################################################\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m#               END OF YOUR CODE                                         #\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m##########################################################################\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ML/alphafold-decoded/tutorials/geometry/geometry.py:104\u001b[0m, in \u001b[0;36mquat_mul\u001b[0;34m(q1, q2)\u001b[0m\n\u001b[1;32m     97\u001b[0m q_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m##########################################################################\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# TODO: Implement batched quaternion multiplication.                     #\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m##########################################################################\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Replace \"pass\" statement with your code\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m a_out \u001b[38;5;241m=\u001b[39m a1\u001b[38;5;241m*\u001b[39ma2 \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mv1\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mv2\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    105\u001b[0m v_out \u001b[38;5;241m=\u001b[39m a1\u001b[38;5;241m*\u001b[39mv2 \u001b[38;5;241m+\u001b[39m a2\u001b[38;5;241m*\u001b[39mv1 \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcross(v1, v2, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    107\u001b[0m q_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((a_out, v_out), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (0) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_forward, test_module_shape, c_s\n",
    "from structure_module.structure_module import BackboneUpdate\n",
    "\n",
    "bb_update = BackboneUpdate(c_s)\n",
    "\n",
    "test_module_shape(bb_update, 'bb_update', control_folder)\n",
    "\n",
    "test_module_forward(bb_update, 'bb_update', 's', 'T_out', control_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compute the prediction of the side-chain torsion angles. These are lines 11-14 in Algorithm 20. We'll start by implementing one layer of this so called AngleResNet, which means one of the lines 12 and 13 (the ResNet has two layers). Implement the initialization and forward pass for `AngleResNetLayer`. Check your code with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_forward, test_module_shape, c\n",
    "from structure_module.structure_module import AngleResNetLayer\n",
    "\n",
    "resnet_layer = AngleResNetLayer(c)\n",
    "\n",
    "test_module_shape(resnet_layer, 'resnet_layer', control_folder)\n",
    "\n",
    "test_module_forward(resnet_layer, 'resnet_layer', 'a', 'a_out', control_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AngleResNet combines two of these layers with additional input and output layers. The output layer predicts the torsion angles in the format of unnormalized (cos(phi), sin(phi)) pairs. These are mapped back to the unit circle by normalization and are used directly in this form, without actually computing phi. Implement the initialization and forward pass for `AngleResNet`, then check your code by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_forward, test_module_shape, c_s, c\n",
    "from structure_module.structure_module import AngleResNet\n",
    "\n",
    "angle_resnet = AngleResNet(c_s, c)\n",
    "\n",
    "test_module_shape(angle_resnet, 'angle_resnet', control_folder)\n",
    "\n",
    "test_module_forward(angle_resnet, 'angle_resnet', ('s', 's_initial'), 'alpha', control_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got all the parts for the Structure Module. Now, we put them all together. Start by implementing the `__init__` method of the Structure Module and check your code with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_shape, c_s, c_z, c, n_layer\n",
    "from structure_module.structure_module import StructureModule\n",
    "\n",
    "sm = StructureModule(c_s, c_z, n_layer, c)\n",
    "\n",
    "test_module_shape(sm, 'structure_module', control_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll implement `process_outputs`. It has two tasks: First, it calls `compute_all_atom_coordinates` to compute the heavy-atom positions from the backbone transforms and the torsion angles. Second, it selects the pseudo-beta positions from all atom positions. These are used by the recycling embedder for the next iteration of the network. They are the positions of the C-beta atoms (for each amino acid except glycine), or the C-alpha atoms (for glycine, which doesn't have a C-beta atom). Implement the method and check your implementation by running the following cell. \n",
    "\n",
    "You don't need to support batched use (this makes selections easier, and we didn't enforce batched support in `compute_all_atom_coordinates`). If you want to implement it and check your implementation, you can remove the 'include_batched=False' flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_method, c_s, c_z, c, n_layer\n",
    "from structure_module.structure_module import StructureModule\n",
    "\n",
    "sm = StructureModule(c_s, c_z, n_layer, c)\n",
    "\n",
    "test_module_method(sm, 'sm_process_outputs', ('T', 'alpha', 'F'), ('pos', 'pos_mask', 'pseudo_beta'), control_folder, lambda *x: sm.process_outputs(*x), include_batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the very last step for the Structure Module, we'll implement the forward pass, which chains together all the modules we implemented earlier. Implement `forward` and check your implementation with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from structure_module.control_values.structure_module_checks import test_module_forward, c_s, c_z, c, n_layer\n",
    "from structure_module.structure_module import StructureModule\n",
    "\n",
    "sm = StructureModule(c_s, c_z, n_layer, c)\n",
    "\n",
    "def check(*args):\n",
    "    output = sm(*args)\n",
    "    return output['angles'], output['frames'], output['final_positions'], output['position_mask'], output['pseudo_beta_positions']\n",
    "\n",
    "\n",
    "test_module_method(sm, 'structure_module', ('s', 'z', 'F'), ('angles', 'frames', 'final_positions', 'position_mask', 'pseudo_beta_positions'), control_folder, check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphafold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
